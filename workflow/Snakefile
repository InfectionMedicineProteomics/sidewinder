#!/usr/bin/env python3
"""Based on the TX-MS web-app implementation Cheetah-MS.
"""

__author__ = 'Joel StrÃ¶baek'
__email__ = 'joel.strobaek@gmail.com'


# TODO:
# - Remove ms2 parameter hard coding!
#       - Set optional click input params with defaults
# - Look into adding logs for all the rules
#       - Diverting STDOUT/STDERR to log files
# - Set temp files
#       - dock_tmp.pdb / lig_tmp.pdb
#       - pdb_A/B.pdb
# - Add some subfolders to the results dir
#       - supp_files: all_xls.txt, target/binder_seq.txt, detected_spectra.txt,
#                     target/binder.pdb
# - MAKE A BETTER FOLDER STRUCTURE FOR THE OUTPUT
# - REMOVE ALL THE STUPID HARD CODING!
# - Refactor the scripts and workflow to actually make it modular...
#       - Many of the steps are interwoven in the current itteration,
#         which (e.g.) inhibits an easy change of docking software

import os
from glob import glob
from pathlib import Path

from snakemake.utils import min_version


min_version("6.0")  # Min version for using modules.

configfile: "config/user_config.yml"


# Convert config paths from string to Path objects.
config_paths = ['output_dir', 'targets_dir', 'binders_dir', 'ms2_file']
config = {k: (v if k not in config_paths else Path(v).resolve()) for k, v in config.items()}

OUTDIR_BASE = config['output_dir']

# New folders
docking_files = 'docking'
sample_files = 'samples'
txms_files =  'txms'

SAMPLES = glob_wildcards(
    os.path.join(
        config['ms2_files'],
        "{sample}.{extension}"
    )
).sample
# MGF_STEM = config["ms2_file"].stem

#OUTDIR = OUTDIR_BASE / MGF_STEM

#MD_OUT = f'/data/{MGF_STEM}'

TARGETS_LIST, = glob_wildcards(f'{config["targets_dir"]}/{{target}}.pdb')

BINDERS_LIST, = glob_wildcards(f'{config["binders_dir"]}/{{binder}}.pdb')

BLOCK_FV = bool(config['block_antibody_non_CDR'])


rule all:
    input:
        expand(
            os.path.join(
                OUTDIR_BASE, txms_files,
                "{MGF_STEM}",
                "{binder}",
                "{target}",
                "{files}"
             ),
             MGF_STEM=SAMPLES,
             binder=BINDERS_LIST,
             target=TARGETS_LIST,
             files=['best_model.pdb', 'best_model_xls.txt']
        )

rule pdb_handling:
    input:
        PDB_a = ancient(f'{config["targets_dir"]}/{{target}}.pdb'),
        PDB_b = ancient(f'{config["binders_dir"]}/{{binder}}.pdb')
    output:
        PDB = os.path.join(OUTDIR_BASE, docking_files, "{binder}", "{target}", "complex_AB.pdb"),  ##   f'{{outdir}}/{{binder}}/{{target}}/complex_AB.pdb',
        seq_a = os.path.join(OUTDIR_BASE, docking_files, "{binder}", "{target}", "chain_A.txt"), # f'{{outdir}}/{{binder}}/{{target}}/chain_A.txt',
        seq_b = os.path.join(OUTDIR_BASE, docking_files, "{binder}", "{target}", "chain_B.txt"),  #f'{{outdir}}/{{binder}}/{{target}}/chain_B.txt',
        pdb_a = os.path.join(OUTDIR_BASE, docking_files, "{binder}", "{target}", "chain_A.pdb"),  #f'{{outdir}}/{{binder}}/{{target}}/chain_A.pdb',
        pdb_b = os.path.join(OUTDIR_BASE, docking_files, "{binder}", "{target}", "chain_B.pdb"), ##f'{{outdir}}/{{binder}}/{{target}}/chain_B.pdb'
    params:
        pdb_handling = 'workflow/scripts/utils/pdb_handling.py',
        outdir = os.path.join(OUTDIR_BASE, docking_files, "{binder}", "{target}") ##f'{{outdir}}/{{binder}}/{{target}}'
    conda:
        'envs/biopython_env.yml'
    shell:
        "python3 {params.pdb_handling} "
        "--pdb1 {input.PDB_a} "
        "--pdb2 {input.PDB_b} "
        "--output_dir {params.outdir}"

if BLOCK_FV:
    # TODO:
    #   - Save process to SQLite DB and make output temporary.
    rule block_pdb:
        input:
            mc_pdb = rules.pdb_handling.input.PDB_a,
            sc_pdb = rules.pdb_handling.output.pdb_a
        output:
            pdb_a = os.path.join(OUTDIR_BASE, docking_files, "{binder}", "{target}", "chain_A_blocked.pdb")
        params:
            fv_blocking = 'workflow/scripts/mdock-block_pdb.py',
            outdir = os.path.join(OUTDIR_BASE, docking_files, "{binder}", "{target}")   ##f'{{outdir}}/{{binder}}/{{target}}'
        conda:
            'envs/biopython_env.yml'
        shell:
            "python3 {params.fv_blocking} "
            "--multi_chain_pdb {input.mc_pdb} "
            "--single_chain_pdb {input.sc_pdb} "
            "--output_dir {params.outdir}"

rule seq2xl:
    input:
        seq_a = rules.pdb_handling.output.seq_a,
        seq_b = rules.pdb_handling.output.seq_b
    output:
        os.path.join(OUTDIR_BASE, docking_files, "{binder}", "{target}", "all_xls.txt")
    params:
        seq2xl = 'workflow/scripts/utils/cheetah/seq2xl.py',
        outdir = os.path.join(OUTDIR_BASE, docking_files, "{binder}", "{target}")   ##f'{{outdir}}/{{binder}}/{{target}}'
    conda:
        'envs/biopython_env.yml'
    shell:
        "python3 {params.seq2xl} "
        "--seq_file1 {input.seq_a} "
        "--seq_file2 {input.seq_b} "
        "--output_dir {params.outdir}"

rule megadock:
    input:
        pdb_a = (rules.block_pdb.output.pdb_a
                 if BLOCK_FV else rules.pdb_handling.output.pdb_a),
        pdb_b = rules.pdb_handling.output.pdb_b
    output:
        os.path.join(OUTDIR_BASE, docking_files, "{binder}_+_{target}_megadock.out")
    params:
        megadock = '/usr/local/megadock/megadock-4.1.1/megadock',
        predictions = config['docking_samples'],
        pdb_a = os.path.join(OUTDIR_BASE, docking_files, "{binder}", "{target}", "chain_A_blocked.pdb") if BLOCK_FV else os.path.join(OUTDIR_BASE, docking_files, "{binder}", "{target}", "chain_A.pdb"),
        pdb_b = os.path.join(OUTDIR_BASE, docking_files, "{binder}", "{target}", "chain_B.pdb"),
    singularity:
        '/srv/data1/home/jo0348st/containers/megadock.sif'  # Move to config.
    threads:
        round(workflow.cores * 0.85)
    log:
        logfile = os.path.join(OUTDIR_BASE, docking_files, "{binder}", "{target}", 'megadock.log')
    shell:
        "{params.megadock} "
        "-R {params.pdb_a} "
        "-L {params.pdb_b} "
        "-o {output} "
        "-N {params.predictions} "
        "> {log.logfile}"

rule msconvert:
    # TODO:
    #   - Sort proper thermoRawFileParser inclusion
    input:
        ms2 = os.path.join(config["ms2_files"], "{MGF_STEM}.mgf")
    output:
        mgf = os.path.join(OUTDIR_BASE, sample_files, "ms2_convert", "{MGF_STEM}.mgf")
    params:
        outdir = os.path.join(OUTDIR_BASE, sample_files, "ms2_convert"),
        thermoRawFileParser = config['thermoRawFileParser']
    conda:
        'envs/mono_env.yml'
    shell:
        "[[ $(sed 's/^.*\.//' <(echo {input.ms2})) == mgf ]]"
        " &&"
        " ln -s {input.ms2} {output.mgf}"
        " ||"
        " mono {params.thermoRawFileParser}"
        " -i={input.ms2}"
        " -o={params.outdir}"
        " -f=0"

rule ms2:
    # TODO: Speed up!
    input:
        mgf = ancient(rules.msconvert.output.mgf),
        xls = ancient(rules.seq2xl.output)
    output:
        sql = os.path.join(OUTDIR_BASE, txms_files, "{MGF_STEM}", "{binder}", "{target}", "ms2_results.sql"),
        img_dir = directory(os.path.join(OUTDIR_BASE, txms_files, "{MGF_STEM}", "{binder}", "{target}", "top_spectra")),
        top_xls = os.path.join(OUTDIR_BASE, txms_files, "{MGF_STEM}", "{binder}", "{target}", "top_xls.txt"),
        mgf_filt = os.path.join(OUTDIR_BASE, txms_files, "{MGF_STEM}", "{binder}", "{target}", "{MGF_STEM}_filtered.mgf")
    params:
        ms2_script = 'workflow/scripts/utils/cheetah/ms2.py',
        outdir = os.path.join(OUTDIR_BASE, txms_files, "{MGF_STEM}", "{binder}", "{target}")
    conda:
        'envs/pyteomics_env.yml'
    shell:
        "python3 {params.ms2_script} "
        "--mgf_file {input.mgf} "
        "--xl_file {input.xls} "
        "--x_linker {params.x_linker} "
        "--output_dir {params.outdir}"

rule modeling:
    # TODO:
    #   - Deal with no-hit-scenarios
    #   - Save euclidean distances to file
    #       - Include aa-numbering and xyz-coord anchors
    #   - Set container image from config.
    input:
        PDB = rules.pdb_handling.output.PDB,
        top_xls = rules.ms2.output.top_xls,
        dock_file = rules.megadock.output
    output:
        top_model = os.path.join(OUTDIR_BASE, txms_files, "{MGF_STEM}", "{binder}", "{target}", "best_model.pdb" ),
        top_xls = os.path.join(OUTDIR_BASE, txms_files, "{MGF_STEM}", "{binder}", "{target}", "best_model_xls.txt"),
        scores = os.path.join(OUTDIR_BASE, txms_files, "{MGF_STEM}", "{binder}", "{target}", "lr_models/scores.csv")
    params:
        cut_off = config['distance_cut_off'],
        n_top_f = config['num_of_top_filters'],
        n_docks = config['model_samples'],
        modeling_script = 'workflow/scripts/hamed_model.py',
        outdir = os.path.join(OUTDIR_BASE, txms_files, "{MGF_STEM}", "{binder}", "{target}")
    conda:
        'envs/biopython_env.yml'
    threads:
        round(workflow.cores * 0.35)
    shell:
        "python3 {params.modeling_script} "
        "--complex_pdb {input.PDB} "
        "--output_dir {params.outdir} "
        "--top_xls_file {input.top_xls} "
        "--dock_file {input.dock_file} "
        "--n_models {params.n_docks} "
        "--n_filters {params.n_top_f} "
        "--cut_off {params.cut_off}"

# rule visualization:
